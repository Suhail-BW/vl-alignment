<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta
      name="description"
      content="How data misalignment shapes vision-language representations"
    />
    <meta
      property="og:title"
      content="How data misalignment shapes vision-language representations"
    />
    <meta
      property="og:description"
      content="How data misalignment shapes vision-language representations"
    />
    <meta
      property="og:url"
      content="https://suhail-BW.github.io/vl-alignment"
    />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />

    <meta
      name="twitter:title"
      content="How data misalignment shapes vision-language representations?"
    />
    <meta
      name="twitter:description"
      content="TWITTER BANNER DESCRIPTION META TAG"
    />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta
      name="twitter:image"
      content="static/images/your_twitter_banner_image.png"
    />
    <meta name="twitter:card" content="summary_large_image" />
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="multimodal learning, contrastive learning" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>How data misalignment shapes vision-language representations?</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico" />
    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="static/css/bulma.min.css" />
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="static/css/index.css" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
  </head>
  <body>
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                How data misalignment shapes vision-language representations?
              </h1>
              <div class="is-size-5 publication-authors">
                <!-- Paper authors -->
                <span class="author-block">
                  <a href="https://suhail-BW.github.io" target="_blank"
                    >Suhail Bashir</a
                  >,</span
                >
                <span class="author-block">
                  <a
                    href="https://people.epfl.ch/jean-philippe.thiran"
                    target="_blank"
                    >Jean-Philippe Thiran</a
                  >,</span
                >
                <span class="author-block">
                  <a
                    href="https://scholar.google.fr/citations?user=r64E9-IAAAAJ&hl"
                    target="_blank"
                    >Benoit Dufumier</a
                  >,</span
                >
                <span class="author-block">
                  <a href="https://javi-castillo.github.io" target="_blank"
                    >Javiera Castillo Navarro</a
                  ></span
                >
              </div>

              <!-- <div class="is-size-5 publication-authors">
                    <span class="author-block">EPFL</span>
                  </div> -->

              <!-- <div class="is-size-5 publication-authors">
                    <span class="author-block"><b>ICLR 2025</b></span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div> -->

              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <p><br /></p>
                  <a href="http://epfl.ch"
                    ><img
                      src="static/images/Fig_EPFL.png"
                      width="150px"
                      margin-left="20px"
                      margin-right="30px"
                      alt="EPFL Logo"
                  /></a>
                  <a
                    href="https://joliot.cea.fr/drf/joliot/en/research/NeuroSpin"
                    ><img
                      src="static/images/neurospin.jpeg"
                      width="180px"
                      style="margin-left: 20px; margin-right: 50px"
                      alt="NeuroSpin Logo"
                  /></a>
                  <a href="https://www.cnam.eu/"
                    ><img
                      src="static/images/CNAM_Logo.svg.png"
                      width="180px"
                      style="margin-left: 20px; margin-right: 50px"
                      alt="NeuroSpin Logo" /></a
                ></span>
                <a href="https://www.oulu.fi/en"
                  ><img
                    src="static/images/University_of_Oulu_logo.jpg"
                    width="90px"
                    height="50px"
                    margin-left="30px"
                    margin-right="30px"
                    alt="EPFL Logo"
                /></a>
              </div>

              <div class="column has-text-centered">
                <!-- <div class="publication-links"> -->
                  <!-- Arxiv PDF link -->
                  <!-- <span class="link-block">
                    <a
                      href="./"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span> -->

                  <!-- Supplementary PDF link -->
                  <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a
                      href="https://github.com/Suhail-BW/2025_vl_alignment"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span> -->

                  <!-- <div class="container is-max-desktop">
                  <div class="columns is-centered">
                  <div class="column is-four-fifths">
                  <div class="content has-text-justified">
                    <p><br></p>
                  <p>
                  <div align="center">
                  <b style="font-size:21px; ">CoMM's new paradigm captures multimodal interactions beyond redundancy.</b> 
                  <p><br></p>
                  </div>
                  <div align="center">
                  <img src="static/images/visual-abstract.png" alt="An Overview of ConGeo" width="80%"/>
                  </div> 
                  We propose <b>CoMM, a contrastive multimodal approach that allows the interplay of multiple modalities and learns multimodal interactions</b>. Unlike previous multimodal models (Cross) that align cross-modal features, CoMM aligns multimodal features in a shared representation space. Multimodal interactions are task-dependent, thus a model needs to capture all of them to generalize to any multimodal task.</p> -->

                  <!-- ArXiv abstract Link -->
                  <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->

              <span class="link-block">
                <!-- Code coming soon -->
                <span class="button is-normal is-rounded is-light is-static">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code coming soon</span>
                </span>
              
                <!-- Paper coming soon -->
                <span class="button is-normal is-rounded is-light is-static ml-2">
                  <span class="icon">
                    <i class="fas fa-file-alt"></i>
                  </span>
                  <span>Paper coming soon</span>
                </span>
              </span>
              
              
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Teaser video-->
    <!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
    <!-- Your video here -->
    <!-- <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Vision-Language (VL) datasets often suffer from misalignment,
                where parts of the image are not described in the accompanying
                text, or vice versa. Current approaches usually address this
                issue using complex filtering pipelines to remove low-quality or
                misaligned examples. This process is resource-intensive and —
                depending on the context — may be infeasible. In this work, we
                systematically investigate the impact of multi-modal
                (mis)alignment on the representation quality of state-of-the-art
                VL models, including CLIP, SLIP, FLAVA, and CoMM. We find that
                CLIP's performance degrades significantly under misalignment,
                even with large-scale training data (over one million samples).
                In contrast, more recent multimodal models such as CoMM, which
                incorporate self-supervised constraints during training,
                demonstrate greater robustness to misaligned data.
              </p>
              <p>
                Our findings highlight the need for self-supervised learning
                strategies that go beyond the widely used cross-modal alignment
                objective, opening several avenues for future research in
                handling weakly aligned multimodal data.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <!-- Image carousel -->
    <!-- End image carousel -->

    <!-- Youtube video -->
    <!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
    <!-- Paper video. -->
    <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
    <!-- Youtube embed code here -->
    <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
    <!-- End youtube video -->
    <!-- <div style="text-align: center; margin-bottom: 20px;">
  <h1>Key Findings</h1>
  <div style="max-width: 900px; margin: auto;">
    <div style="text-align: center; margin-bottom: 40px;">
      <h3>Experiment 1: Alignment</h3>
      <img src="static/images/mm_combined_box_line_alignment.png" alt="Multimodal Evaluation on Data Alignment" style="width: 100%; border: 1px solid #ddd; border-radius: 4px;">
    </div>
    <div style="text-align: center;">
      <h3>Experiment 2: Scale</h3>
      <img src="static/images/mm_combined_box_line_scale.png" alt="Multimodal Evaluation on Data Scale" style="width: 100%; border: 1px solid #ddd; border-radius: 4px;">
    </div>
  </div>
</div>

<div style="text-align: center;">
  <h2>Vision Evaluation</h2>
  <div style="max-width: 900px; margin: auto;">
    <div style="text-align: center; margin-bottom: 40px;">
      <h3>Experiment 1: Alignment</h3>
      <img src="static/images/combined_box_line_alignment.png" alt="Vision Evaluation on Data Alignment" style="width: 100%; border: 1px solid #ddd; border-radius: 4px;">
    </div>
    <div style="text-align: center;">
      <h3>Experiment 2: Scale</h3>
      <img src="static/images/combined_box_line_scale.png" alt="Vision Evaluation on Data Scale" style="width: 100%; border: 1px solid #ddd; border-radius: 4px;">
    </div>
  </div>
</div> -->

    <!-- Video carousel -->
    <!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
    <!-- Your video file here -->
    <!-- <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
    <!-- Your video file here -->
    <!-- <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
    <!-- Your video file here -->
    <!-- <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
    <!-- End video carousel -->

    <!-- Paper poster -->
    <!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/CoMM_poster_ICLR2025.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
    <!--End paper poster -->

    <!--BibTex citation -->
    <!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{dufumier2025what,
title={How data misalignment shapes vision-language representations?},
author={Dufumier, Benoit and Castillo-Navarro, Javiera and Tuia, Devis and Thiran, Jean-Philippe},
booktitle={International Conference on Learning Representations},
year={2025}
}</code></pre>
  </div>
</section> -->
    <!--End BibTex citation -->

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This page was built using the
                <a
                  href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank"
                  >Academic Project Page Template</a
                >
                which was adopted from the <a
                  href="https://nerfies.github.io"
                  target="_blank"
                  >Nerfies</a
                > project page. You are free to borrow the source code of this
                website, we just ask that you link back to this page in the
                footer. <br />
                This website is licensed under a
                <a
                  rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/"
                  target="_blank"
                  >Creative Commons Attribution-ShareAlike 4.0 International
                  License</a
                >.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->
  </body>
</html>
